2021-02-22 16:29:13,324 Corpus: "Corpus: 20 train + 347 dev + 368 test sentences"
2021-02-22 16:29:13,324 ----------------------------------------------------------------------------------------------------
2021-02-22 16:29:13,324 Parameters:
2021-02-22 16:29:13,324  - learning_rate: "5e-05"
2021-02-22 16:29:13,324  - mini_batch_size: "32"
2021-02-22 16:29:13,324  - patience: "3"
2021-02-22 16:29:13,324  - anneal_factor: "0.5"
2021-02-22 16:29:13,324  - max_epochs: "10"
2021-02-22 16:29:13,324  - shuffle: "True"
2021-02-22 16:29:13,324  - train_with_dev: "False"
2021-02-22 16:29:13,324  - batch_growth_annealing: "False"
2021-02-22 16:29:13,324 ----------------------------------------------------------------------------------------------------
2021-02-22 16:29:13,324 Model training base path: "resources/v3/fewshot-moviecomplex-synonyms-to-conll3-k5"
2021-02-22 16:29:13,324 ----------------------------------------------------------------------------------------------------
2021-02-22 16:29:13,324 Device: cuda:0
2021-02-22 16:29:13,324 ----------------------------------------------------------------------------------------------------
2021-02-22 16:29:13,324 Embeddings storage mode: none
2021-02-22 16:29:13,330 ----------------------------------------------------------------------------------------------------
2021-02-22 16:29:15,159 epoch 1 - iter 1/1 - loss 0.63428187 - samples/sec: 17.91 - lr: 0.000045
2021-02-22 16:29:15,160 ----------------------------------------------------------------------------------------------------
2021-02-22 16:29:15,160 EPOCH 1 done: loss 0.6343 - lr 0.0000452
2021-02-22 16:29:39,189 DEV : loss 0.5537646412849426 - score 0.2371
2021-02-22 16:29:39,192 BAD EPOCHS (no improvement): 4
2021-02-22 16:29:39,194 ----------------------------------------------------------------------------------------------------
2021-02-22 16:29:40,998 epoch 2 - iter 1/1 - loss 0.74808341 - samples/sec: 18.13 - lr: 0.000040
2021-02-22 16:29:40,999 ----------------------------------------------------------------------------------------------------
2021-02-22 16:29:40,999 EPOCH 2 done: loss 0.7481 - lr 0.0000397
2021-02-22 16:30:06,160 DEV : loss 0.2608458995819092 - score 0.1273
2021-02-22 16:30:06,164 BAD EPOCHS (no improvement): 4
2021-02-22 16:30:06,165 ----------------------------------------------------------------------------------------------------
2021-02-22 16:30:07,956 epoch 3 - iter 1/1 - loss 0.46294525 - samples/sec: 18.26 - lr: 0.000033
2021-02-22 16:30:07,957 ----------------------------------------------------------------------------------------------------
2021-02-22 16:30:07,957 EPOCH 3 done: loss 0.4629 - lr 0.0000327
2021-02-22 16:30:31,955 DEV : loss 0.2072492390871048 - score 0.0031
2021-02-22 16:30:31,958 BAD EPOCHS (no improvement): 4
2021-02-22 16:30:31,960 ----------------------------------------------------------------------------------------------------
2021-02-22 16:30:33,726 epoch 4 - iter 1/1 - loss 0.35926342 - samples/sec: 18.53 - lr: 0.000025
2021-02-22 16:30:33,727 ----------------------------------------------------------------------------------------------------
2021-02-22 16:30:33,727 EPOCH 4 done: loss 0.3593 - lr 0.0000250
2021-02-22 16:30:57,833 DEV : loss 0.1977940946817398 - score 0.0
2021-02-22 16:30:57,837 BAD EPOCHS (no improvement): 4
2021-02-22 16:30:57,841 ----------------------------------------------------------------------------------------------------
2021-02-22 16:30:59,628 epoch 5 - iter 1/1 - loss 0.36911431 - samples/sec: 18.29 - lr: 0.000017
2021-02-22 16:30:59,629 ----------------------------------------------------------------------------------------------------
2021-02-22 16:30:59,630 EPOCH 5 done: loss 0.3691 - lr 0.0000173
2021-02-22 16:31:24,958 DEV : loss 0.1853073388338089 - score 0.0092
2021-02-22 16:31:24,963 BAD EPOCHS (no improvement): 4
2021-02-22 16:31:24,965 ----------------------------------------------------------------------------------------------------
2021-02-22 16:31:26,748 epoch 6 - iter 1/1 - loss 0.31041244 - samples/sec: 18.35 - lr: 0.000010
2021-02-22 16:31:26,749 ----------------------------------------------------------------------------------------------------
2021-02-22 16:31:26,749 EPOCH 6 done: loss 0.3104 - lr 0.0000103
2021-02-22 16:31:50,809 DEV : loss 0.17587319016456604 - score 0.0239
2021-02-22 16:31:50,813 BAD EPOCHS (no improvement): 4
2021-02-22 16:31:50,815 ----------------------------------------------------------------------------------------------------
2021-02-22 16:31:52,583 epoch 7 - iter 1/1 - loss 0.29859766 - samples/sec: 18.51 - lr: 0.000005
2021-02-22 16:31:52,584 ----------------------------------------------------------------------------------------------------
2021-02-22 16:31:52,584 EPOCH 7 done: loss 0.2986 - lr 0.0000048
2021-02-22 16:32:16,684 DEV : loss 0.1701064556837082 - score 0.0603
2021-02-22 16:32:16,688 BAD EPOCHS (no improvement): 4
2021-02-22 16:32:16,690 ----------------------------------------------------------------------------------------------------
2021-02-22 16:32:18,481 epoch 8 - iter 1/1 - loss 0.27561915 - samples/sec: 18.26 - lr: 0.000001
2021-02-22 16:32:18,482 ----------------------------------------------------------------------------------------------------
2021-02-22 16:32:18,482 EPOCH 8 done: loss 0.2756 - lr 0.0000012
2021-02-22 16:32:43,681 DEV : loss 0.16759654879570007 - score 0.0654
2021-02-22 16:32:43,685 BAD EPOCHS (no improvement): 4
2021-02-22 16:32:43,687 ----------------------------------------------------------------------------------------------------
2021-02-22 16:32:45,462 epoch 9 - iter 1/1 - loss 0.28698650 - samples/sec: 18.42 - lr: 0.000000
2021-02-22 16:32:45,463 ----------------------------------------------------------------------------------------------------
2021-02-22 16:32:45,463 EPOCH 9 done: loss 0.2870 - lr 0.0000000
2021-02-22 16:33:09,563 DEV : loss 0.16695311665534973 - score 0.0705
2021-02-22 16:33:09,567 BAD EPOCHS (no improvement): 4
2021-02-22 16:33:09,583 ----------------------------------------------------------------------------------------------------
2021-02-22 16:33:11,371 epoch 10 - iter 1/1 - loss 0.28533515 - samples/sec: 18.30 - lr: 0.000001
2021-02-22 16:33:11,372 ----------------------------------------------------------------------------------------------------
2021-02-22 16:33:11,372 EPOCH 10 done: loss 0.2853 - lr 0.0000012
2021-02-22 16:33:36,768 DEV : loss 0.16695310175418854 - score 0.0705
2021-02-22 16:33:36,772 BAD EPOCHS (no improvement): 4
2021-02-22 16:33:41,045 ----------------------------------------------------------------------------------------------------
2021-02-22 16:33:41,046 Testing using best model ...
2021-02-22 16:34:05,422 0.2473  0.0413  0.0708
2021-02-22 16:34:05,422
Results:
- F1-score (micro) 0.0708
- F1-score (macro) 0.0534

By class:
Location   tp: 17 - fp: 11 - fn: 163 - precision: 0.6071 - recall: 0.0944 - f1-score: 0.1635
Miscellaneous tp: 0 - fp: 2 - fn: 57 - precision: 0.0000 - recall: 0.0000 - f1-score: 0.0000
Organization tp: 0 - fp: 3 - fn: 140 - precision: 0.0000 - recall: 0.0000 - f1-score: 0.0000
Person     tp: 6 - fp: 54 - fn: 174 - precision: 0.1000 - recall: 0.0333 - f1-score: 0.0500
2021-02-22 16:34:05,422 ----------------------------------------------------------------------------------------------------
0
<bound method Sentence.to_tagged_string of Sentence: "The Parlament of the United Kingdom is discussing a variety of topics ."   [− Tokens: 13]>
-------------
1
<bound method Sentence.to_tagged_string of Sentence: "A man fell in love with a woman . This takes place in the last century . The film received the Golden Love Film Award ."   [− Tokens: 26  − Token-Labels: "A man <B-Story> fell in <I-Story> love <I-Story> with <I-Story> a <I-Story> woman <I-Story> . This takes place in the last century . The film received the Golden Love Film Award ."]>
-------------
2
<bound method Sentence.to_tagged_string of Sentence: "The Company of Coca Cola was invented in 1901 ."   [− Tokens: 10]>
-------------
3
<bound method Sentence.to_tagged_string of Sentence: "This is very frustrating ! I was smiling since I saw you ."   [− Tokens: 13]>
-------------
4
<bound method Sentence.to_tagged_string of Sentence: "The Green Party received only a small percentage of the vote ."   [− Tokens: 12]>
-------------
5
<bound method Sentence.to_tagged_string of Sentence: "Bayern Munich won the german soccer series the sixth time in a row ."   [− Tokens: 14]>
-------------
